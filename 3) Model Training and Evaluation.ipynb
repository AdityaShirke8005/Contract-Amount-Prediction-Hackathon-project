{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98b7a297",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e59a070",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>original_amount</th>\n",
       "      <th>revised_amount</th>\n",
       "      <th>year</th>\n",
       "      <th>GDP_growth</th>\n",
       "      <th>inflation</th>\n",
       "      <th>manufacturing_value_added</th>\n",
       "      <th>official_exchange_rate</th>\n",
       "      <th>ENT  (ENTERTAIN)</th>\n",
       "      <th>GENERAL</th>\n",
       "      <th>GS   (GEN SERV)</th>\n",
       "      <th>HUD (GEN SERV-HUD)</th>\n",
       "      <th>INS  (INSTRUCTOR)</th>\n",
       "      <th>IT/TECH</th>\n",
       "      <th>LS   (LEASE SVCS)</th>\n",
       "      <th>LW   (DON'T USE)</th>\n",
       "      <th>PRO  (PRO SERVIC)</th>\n",
       "      <th>RISK - HR / INS</th>\n",
       "      <th>RNT  (EQUIP RENT)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1037830.0</td>\n",
       "      <td>877933.38</td>\n",
       "      <td>2019</td>\n",
       "      <td>1.841875</td>\n",
       "      <td>1.464833</td>\n",
       "      <td>11.798116</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>6000.00</td>\n",
       "      <td>2015</td>\n",
       "      <td>2.241921</td>\n",
       "      <td>2.130110</td>\n",
       "      <td>11.258856</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>4000.00</td>\n",
       "      <td>2010</td>\n",
       "      <td>2.061593</td>\n",
       "      <td>8.002800</td>\n",
       "      <td>10.700371</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3500.0</td>\n",
       "      <td>3500.00</td>\n",
       "      <td>2010</td>\n",
       "      <td>2.061593</td>\n",
       "      <td>8.002800</td>\n",
       "      <td>10.700371</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>32000.0</td>\n",
       "      <td>91344.00</td>\n",
       "      <td>2013</td>\n",
       "      <td>2.294439</td>\n",
       "      <td>1.812210</td>\n",
       "      <td>11.058037</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  original_amount  revised_amount  year  GDP_growth  inflation  \\\n",
       "0           0        1037830.0       877933.38  2019    1.841875   1.464833   \n",
       "1           1           6000.0         6000.00  2015    2.241921   2.130110   \n",
       "2           2           4000.0         4000.00  2010    2.061593   8.002800   \n",
       "3           3           3500.0         3500.00  2010    2.061593   8.002800   \n",
       "4           4          32000.0        91344.00  2013    2.294439   1.812210   \n",
       "\n",
       "   manufacturing_value_added  official_exchange_rate  ENT  (ENTERTAIN)  \\\n",
       "0                  11.798116                       1                 0   \n",
       "1                  11.258856                       1                 0   \n",
       "2                  10.700371                       1                 0   \n",
       "3                  10.700371                       1                 0   \n",
       "4                  11.058037                       1                 0   \n",
       "\n",
       "   GENERAL  GS   (GEN SERV)  HUD (GEN SERV-HUD)  INS  (INSTRUCTOR)  IT/TECH  \\\n",
       "0        0                1                   0                  0        0   \n",
       "1        0                1                   0                  0        0   \n",
       "2        0                1                   0                  0        0   \n",
       "3        0                1                   0                  0        0   \n",
       "4        1                0                   0                  0        0   \n",
       "\n",
       "   LS   (LEASE SVCS)  LW   (DON'T USE)  PRO  (PRO SERVIC)  RISK - HR / INS  \\\n",
       "0                  0                 0                  0                0   \n",
       "1                  0                 0                  0                0   \n",
       "2                  0                 0                  0                0   \n",
       "3                  0                 0                  0                0   \n",
       "4                  0                 0                  0                0   \n",
       "\n",
       "   RNT  (EQUIP RENT)  \n",
       "0                  0  \n",
       "1                  0  \n",
       "2                  0  \n",
       "3                  0  \n",
       "4                  0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Final_contract_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9a98732",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                    0\n",
       "original_amount              17\n",
       "revised_amount               17\n",
       "year                          0\n",
       "GDP_growth                    0\n",
       "inflation                     0\n",
       "manufacturing_value_added     0\n",
       "official_exchange_rate        0\n",
       "ENT  (ENTERTAIN)              0\n",
       "GENERAL                       0\n",
       "GS   (GEN SERV)               0\n",
       "HUD (GEN SERV-HUD)            0\n",
       "INS  (INSTRUCTOR)             0\n",
       "IT/TECH                       0\n",
       "LS   (LEASE SVCS)             0\n",
       "LW   (DON'T USE)              0\n",
       "PRO  (PRO SERVIC)             0\n",
       "RISK - HR / INS               0\n",
       "RNT  (EQUIP RENT)             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660d9575",
   "metadata": {},
   "source": [
    "Dropping Null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd0005ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['original_amount', 'revised_amount'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a2c862f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                   0\n",
       "original_amount              0\n",
       "revised_amount               0\n",
       "year                         0\n",
       "GDP_growth                   0\n",
       "inflation                    0\n",
       "manufacturing_value_added    0\n",
       "official_exchange_rate       0\n",
       "ENT  (ENTERTAIN)             0\n",
       "GENERAL                      0\n",
       "GS   (GEN SERV)              0\n",
       "HUD (GEN SERV-HUD)           0\n",
       "INS  (INSTRUCTOR)            0\n",
       "IT/TECH                      0\n",
       "LS   (LEASE SVCS)            0\n",
       "LW   (DON'T USE)             0\n",
       "PRO  (PRO SERVIC)            0\n",
       "RISK - HR / INS              0\n",
       "RNT  (EQUIP RENT)            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f21bf30",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7237 entries, 0 to 7253\n",
      "Data columns (total 19 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   Unnamed: 0                 7237 non-null   int64  \n",
      " 1   original_amount            7237 non-null   float64\n",
      " 2   revised_amount             7237 non-null   float64\n",
      " 3   year                       7237 non-null   int64  \n",
      " 4   GDP_growth                 7237 non-null   float64\n",
      " 5   inflation                  7237 non-null   float64\n",
      " 6   manufacturing_value_added  7237 non-null   float64\n",
      " 7   official_exchange_rate     7237 non-null   int64  \n",
      " 8   ENT  (ENTERTAIN)           7237 non-null   int64  \n",
      " 9   GENERAL                    7237 non-null   int64  \n",
      " 10  GS   (GEN SERV)            7237 non-null   int64  \n",
      " 11  HUD (GEN SERV-HUD)         7237 non-null   int64  \n",
      " 12  INS  (INSTRUCTOR)          7237 non-null   int64  \n",
      " 13  IT/TECH                    7237 non-null   int64  \n",
      " 14  LS   (LEASE SVCS)          7237 non-null   int64  \n",
      " 15  LW   (DON'T USE)           7237 non-null   int64  \n",
      " 16  PRO  (PRO SERVIC)          7237 non-null   int64  \n",
      " 17  RISK - HR / INS            7237 non-null   int64  \n",
      " 18  RNT  (EQUIP RENT)          7237 non-null   int64  \n",
      "dtypes: float64(5), int64(14)\n",
      "memory usage: 1.1 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c98335f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['original_amount', 'GDP_growth', 'inflation', 'manufacturing_value_added']]\n",
    "y = df['revised_amount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4dc8a983",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83b69f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "497d40d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89c6594b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e73ccd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95181cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=X_train_scaled.shape[1], activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8520e31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(loss='mean_squared_error', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36d97940",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "163/163 [==============================] - 1s 2ms/step - loss: 1110925901824.0000 - val_loss: 2105584254976.0000\n",
      "Epoch 2/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 1110896541696.0000 - val_loss: 2105548079104.0000\n",
      "Epoch 3/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 1110816063488.0000 - val_loss: 2105463799808.0000\n",
      "Epoch 4/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 1110699409408.0000 - val_loss: 2105356451840.0000\n",
      "Epoch 5/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 1110515515392.0000 - val_loss: 2105177014272.0000\n",
      "Epoch 6/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 1110246817792.0000 - val_loss: 2104941740032.0000\n",
      "Epoch 7/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 1109882568704.0000 - val_loss: 2104623890432.0000\n",
      "Epoch 8/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 1109409660928.0000 - val_loss: 2104223858688.0000\n",
      "Epoch 9/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 1108837269504.0000 - val_loss: 2103744135168.0000\n",
      "Epoch 10/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 1108124499968.0000 - val_loss: 2103164665856.0000\n",
      "Epoch 11/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 1107280265216.0000 - val_loss: 2102472081408.0000\n",
      "Epoch 12/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 1106327109632.0000 - val_loss: 2101733228544.0000\n",
      "Epoch 13/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 1105282465792.0000 - val_loss: 2100901707776.0000\n",
      "Epoch 14/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 1104094560256.0000 - val_loss: 2100051705856.0000\n",
      "Epoch 15/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 1102815559680.0000 - val_loss: 2098966822912.0000\n",
      "Epoch 16/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 1101378355200.0000 - val_loss: 2098040799232.0000\n",
      "Epoch 17/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 1099836686336.0000 - val_loss: 2096690757632.0000\n",
      "Epoch 18/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 1098232430592.0000 - val_loss: 2095585951744.0000\n",
      "Epoch 19/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 1096581120000.0000 - val_loss: 2094253211648.0000\n",
      "Epoch 20/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 1094789431296.0000 - val_loss: 2092958744576.0000\n",
      "Epoch 21/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 1092905664512.0000 - val_loss: 2091616174080.0000\n",
      "Epoch 22/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 1090974646272.0000 - val_loss: 2090206101504.0000\n",
      "Epoch 23/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 1089031110656.0000 - val_loss: 2088782266368.0000\n",
      "Epoch 24/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 1086971641856.0000 - val_loss: 2087355678720.0000\n",
      "Epoch 25/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 1084869705728.0000 - val_loss: 2085901828096.0000\n",
      "Epoch 26/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 1082728185856.0000 - val_loss: 2084456890368.0000\n",
      "Epoch 27/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 1080534237184.0000 - val_loss: 2082966863872.0000\n",
      "Epoch 28/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 1078285828096.0000 - val_loss: 2081493090304.0000\n",
      "Epoch 29/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 1075954319360.0000 - val_loss: 2080076857344.0000\n",
      "Epoch 30/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 1073604067328.0000 - val_loss: 2078610292736.0000\n",
      "Epoch 31/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 1071242346496.0000 - val_loss: 2077049487360.0000\n",
      "Epoch 32/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 1069108363264.0000 - val_loss: 2075604811776.0000\n",
      "Epoch 33/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 1066595123200.0000 - val_loss: 2074265911296.0000\n",
      "Epoch 34/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 1064405958656.0000 - val_loss: 2072917049344.0000\n",
      "Epoch 35/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 1061935185920.0000 - val_loss: 2071586406400.0000\n",
      "Epoch 36/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 1059579953152.0000 - val_loss: 2070137405440.0000\n",
      "Epoch 37/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 1057174847488.0000 - val_loss: 2068834418688.0000\n",
      "Epoch 38/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 1054929584128.0000 - val_loss: 2067576389632.0000\n",
      "Epoch 39/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 1052377350144.0000 - val_loss: 2066328059904.0000\n",
      "Epoch 40/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 1049981943808.0000 - val_loss: 2065079336960.0000\n",
      "Epoch 41/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 1047561043968.0000 - val_loss: 2063883567104.0000\n",
      "Epoch 42/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 1045180710912.0000 - val_loss: 2062668005376.0000\n",
      "Epoch 43/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 1042742640640.0000 - val_loss: 2061552975872.0000\n",
      "Epoch 44/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 1040338059264.0000 - val_loss: 2060427591680.0000\n",
      "Epoch 45/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 1037936427008.0000 - val_loss: 2059347558400.0000\n",
      "Epoch 46/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 1035521228800.0000 - val_loss: 2058274471936.0000\n",
      "Epoch 47/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 1033080799232.0000 - val_loss: 2057231794176.0000\n",
      "Epoch 48/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 1030669729792.0000 - val_loss: 2056242069504.0000\n",
      "Epoch 49/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 1028187357184.0000 - val_loss: 2055275413504.0000\n",
      "Epoch 50/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 1025672282112.0000 - val_loss: 2054236143616.0000\n",
      "Epoch 51/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 1023391694848.0000 - val_loss: 2053305925632.0000\n",
      "Epoch 52/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 1020668280832.0000 - val_loss: 2052354867200.0000\n",
      "Epoch 53/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 1018266648576.0000 - val_loss: 2051351117824.0000\n",
      "Epoch 54/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 1015880876032.0000 - val_loss: 2050536243200.0000\n",
      "Epoch 55/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 1013276868608.0000 - val_loss: 2049542324224.0000\n",
      "Epoch 56/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 1010584911872.0000 - val_loss: 2048686817280.0000\n",
      "Epoch 57/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 1008045850624.0000 - val_loss: 2047871549440.0000\n",
      "Epoch 58/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 1005466288128.0000 - val_loss: 2046971740160.0000\n",
      "Epoch 59/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 1002760765440.0000 - val_loss: 2046188847104.0000\n",
      "Epoch 60/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 1000102428672.0000 - val_loss: 2045223895040.0000\n",
      "Epoch 61/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 997441470464.0000 - val_loss: 2044389621760.0000\n",
      "Epoch 62/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 994637578240.0000 - val_loss: 2043530051584.0000\n",
      "Epoch 63/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 991955910656.0000 - val_loss: 2042655670272.0000\n",
      "Epoch 64/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 989302358016.0000 - val_loss: 2041857572864.0000\n",
      "Epoch 65/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 986191691776.0000 - val_loss: 2041004032000.0000\n",
      "Epoch 66/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163/163 [==============================] - 0s 1ms/step - loss: 983812669440.0000 - val_loss: 2040142364672.0000\n",
      "Epoch 67/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 980549042176.0000 - val_loss: 2039318708224.0000\n",
      "Epoch 68/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 977518395392.0000 - val_loss: 2038547087360.0000\n",
      "Epoch 69/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 974493974528.0000 - val_loss: 2037575581696.0000\n",
      "Epoch 70/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 971364564992.0000 - val_loss: 2036727414784.0000\n",
      "Epoch 71/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 968632172544.0000 - val_loss: 2035890782208.0000\n",
      "Epoch 72/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 965186289664.0000 - val_loss: 2035030032384.0000\n",
      "Epoch 73/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 961981448192.0000 - val_loss: 2034124324864.0000\n",
      "Epoch 74/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 958715527168.0000 - val_loss: 2033287823360.0000\n",
      "Epoch 75/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 955469070336.0000 - val_loss: 2032394436608.0000\n",
      "Epoch 76/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 952415158272.0000 - val_loss: 2031524380672.0000\n",
      "Epoch 77/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 948743962624.0000 - val_loss: 2030631518208.0000\n",
      "Epoch 78/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 945609572352.0000 - val_loss: 2029737345024.0000\n",
      "Epoch 79/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 942157660160.0000 - val_loss: 2028879216640.0000\n",
      "Epoch 80/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 938607509504.0000 - val_loss: 2027973771264.0000\n",
      "Epoch 81/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 935096418304.0000 - val_loss: 2027097292800.0000\n",
      "Epoch 82/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 931508125696.0000 - val_loss: 2026227761152.0000\n",
      "Epoch 83/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 927678529536.0000 - val_loss: 2025241837568.0000\n",
      "Epoch 84/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 923900837888.0000 - val_loss: 2024289206272.0000\n",
      "Epoch 85/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 920124915712.0000 - val_loss: 2023372357632.0000\n",
      "Epoch 86/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 916893073408.0000 - val_loss: 2022457344000.0000\n",
      "Epoch 87/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 912611934208.0000 - val_loss: 2021474959360.0000\n",
      "Epoch 88/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 908411469824.0000 - val_loss: 2020547100672.0000\n",
      "Epoch 89/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 904488812544.0000 - val_loss: 2019579658240.0000\n",
      "Epoch 90/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 900378918912.0000 - val_loss: 2018815377408.0000\n",
      "Epoch 91/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 896297533440.0000 - val_loss: 2017635991552.0000\n",
      "Epoch 92/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 892148514816.0000 - val_loss: 2016688996352.0000\n",
      "Epoch 93/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 887888019456.0000 - val_loss: 2015681183744.0000\n",
      "Epoch 94/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 883785465856.0000 - val_loss: 2014685560832.0000\n",
      "Epoch 95/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 879461335040.0000 - val_loss: 2013701079040.0000\n",
      "Epoch 96/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 875011571712.0000 - val_loss: 2012734423040.0000\n",
      "Epoch 97/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 870714769408.0000 - val_loss: 2011704852480.0000\n",
      "Epoch 98/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 866447392768.0000 - val_loss: 2010783023104.0000\n",
      "Epoch 99/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 861570859008.0000 - val_loss: 2009641385984.0000\n",
      "Epoch 100/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 856894406656.0000 - val_loss: 2008582717440.0000\n",
      "Epoch 101/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 852172603392.0000 - val_loss: 2007755128832.0000\n",
      "Epoch 102/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 847414951936.0000 - val_loss: 2006585835520.0000\n",
      "Epoch 103/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 842610376704.0000 - val_loss: 2005487058944.0000\n",
      "Epoch 104/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 837926191104.0000 - val_loss: 2004478984192.0000\n",
      "Epoch 105/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 833160806400.0000 - val_loss: 2003458326528.0000\n",
      "Epoch 106/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 828364554240.0000 - val_loss: 2002452480000.0000\n",
      "Epoch 107/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 823607558144.0000 - val_loss: 2001426448384.0000\n",
      "Epoch 108/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 818635407360.0000 - val_loss: 2000719052800.0000\n",
      "Epoch 109/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 813648445440.0000 - val_loss: 1999383035904.0000\n",
      "Epoch 110/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 808655912960.0000 - val_loss: 1998345732096.0000\n",
      "Epoch 111/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 803378954240.0000 - val_loss: 1997313015808.0000\n",
      "Epoch 112/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 798188830720.0000 - val_loss: 1996289867776.0000\n",
      "Epoch 113/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 793086853120.0000 - val_loss: 1995254267904.0000\n",
      "Epoch 114/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 787836960768.0000 - val_loss: 1994239508480.0000\n",
      "Epoch 115/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 782644281344.0000 - val_loss: 1993214394368.0000\n",
      "Epoch 116/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 777638248448.0000 - val_loss: 1992252194816.0000\n",
      "Epoch 117/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 772447076352.0000 - val_loss: 1991234682880.0000\n",
      "Epoch 118/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 766708154368.0000 - val_loss: 1990455197696.0000\n",
      "Epoch 119/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 761374834688.0000 - val_loss: 1989208965120.0000\n",
      "Epoch 120/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 755874398208.0000 - val_loss: 1988220026880.0000\n",
      "Epoch 121/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 750155726848.0000 - val_loss: 1987192160256.0000\n",
      "Epoch 122/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 744678948864.0000 - val_loss: 1986178056192.0000\n",
      "Epoch 123/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 739111796736.0000 - val_loss: 1985183875072.0000\n",
      "Epoch 124/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 733503553536.0000 - val_loss: 1984251297792.0000\n",
      "Epoch 125/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 727947083776.0000 - val_loss: 1983182143488.0000\n",
      "Epoch 126/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 722164252672.0000 - val_loss: 1982237507584.0000\n",
      "Epoch 127/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 717045432320.0000 - val_loss: 1981235200000.0000\n",
      "Epoch 128/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 710911393792.0000 - val_loss: 1980237217792.0000\n",
      "Epoch 129/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 705043562496.0000 - val_loss: 1979278950400.0000\n",
      "Epoch 130/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 699233730560.0000 - val_loss: 1978266157056.0000\n",
      "Epoch 131/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163/163 [==============================] - 0s 1ms/step - loss: 693446705152.0000 - val_loss: 1977232916480.0000\n",
      "Epoch 132/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 687325511680.0000 - val_loss: 1976237162496.0000\n",
      "Epoch 133/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 681524264960.0000 - val_loss: 1975209295872.0000\n",
      "Epoch 134/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 675525099520.0000 - val_loss: 1974232154112.0000\n",
      "Epoch 135/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 669525213184.0000 - val_loss: 1973726609408.0000\n",
      "Epoch 136/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 663373545472.0000 - val_loss: 1972250214400.0000\n",
      "Epoch 137/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 657245798400.0000 - val_loss: 1971229163520.0000\n",
      "Epoch 138/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 651310071808.0000 - val_loss: 1970260803584.0000\n",
      "Epoch 139/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 645947195392.0000 - val_loss: 1969292836864.0000\n",
      "Epoch 140/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 640225968128.0000 - val_loss: 1968439689216.0000\n",
      "Epoch 141/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 633845579776.0000 - val_loss: 1967518253056.0000\n",
      "Epoch 142/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 628787118080.0000 - val_loss: 1966627487744.0000\n",
      "Epoch 143/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 622115684352.0000 - val_loss: 1965693206528.0000\n",
      "Epoch 144/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 616330493952.0000 - val_loss: 1964693520384.0000\n",
      "Epoch 145/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 610163490816.0000 - val_loss: 1963995037696.0000\n",
      "Epoch 146/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 604104425472.0000 - val_loss: 1962970447872.0000\n",
      "Epoch 147/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 598211952640.0000 - val_loss: 1961869836288.0000\n",
      "Epoch 148/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 592294903808.0000 - val_loss: 1961107390464.0000\n",
      "Epoch 149/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 586252812288.0000 - val_loss: 1960009007104.0000\n",
      "Epoch 150/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 580144791552.0000 - val_loss: 1959071186944.0000\n",
      "Epoch 151/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 573852221440.0000 - val_loss: 1958356451328.0000\n",
      "Epoch 152/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 567798071296.0000 - val_loss: 1957250072576.0000\n",
      "Epoch 153/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 561719345152.0000 - val_loss: 1956574527488.0000\n",
      "Epoch 154/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 555260510208.0000 - val_loss: 1955422928896.0000\n",
      "Epoch 155/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 549116248064.0000 - val_loss: 1954749480960.0000\n",
      "Epoch 156/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 543371722752.0000 - val_loss: 1953602600960.0000\n",
      "Epoch 157/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 537068765184.0000 - val_loss: 1952828489728.0000\n",
      "Epoch 158/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 530951274496.0000 - val_loss: 1951863013376.0000\n",
      "Epoch 159/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 524968656896.0000 - val_loss: 1951056396288.0000\n",
      "Epoch 160/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 518861094912.0000 - val_loss: 1950193287168.0000\n",
      "Epoch 161/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 512883228672.0000 - val_loss: 1949287841792.0000\n",
      "Epoch 162/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 506927644672.0000 - val_loss: 1948455010304.0000\n",
      "Epoch 163/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 501299609600.0000 - val_loss: 1947683520512.0000\n",
      "Epoch 164/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 495095054336.0000 - val_loss: 1946833649664.0000\n",
      "Epoch 165/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 489001385984.0000 - val_loss: 1946407665664.0000\n",
      "Epoch 166/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 483035545600.0000 - val_loss: 1945323044864.0000\n",
      "Epoch 167/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 477257072640.0000 - val_loss: 1944406851584.0000\n",
      "Epoch 168/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 471263739904.0000 - val_loss: 1943798808576.0000\n",
      "Epoch 169/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 465499029504.0000 - val_loss: 1942911713280.0000\n",
      "Epoch 170/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 459702468608.0000 - val_loss: 1942157131776.0000\n",
      "Epoch 171/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 453886279680.0000 - val_loss: 1941432303616.0000\n",
      "Epoch 172/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 448085852160.0000 - val_loss: 1940722024448.0000\n",
      "Epoch 173/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 442520698880.0000 - val_loss: 1940335624192.0000\n",
      "Epoch 174/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 436856127488.0000 - val_loss: 1939299762176.0000\n",
      "Epoch 175/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 431222030336.0000 - val_loss: 1938619367424.0000\n",
      "Epoch 176/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 425486745600.0000 - val_loss: 1938170052608.0000\n",
      "Epoch 177/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 420437098496.0000 - val_loss: 1937280598016.0000\n",
      "Epoch 178/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 414841044992.0000 - val_loss: 1936687628288.0000\n",
      "Epoch 179/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 409672941568.0000 - val_loss: 1936143286272.0000\n",
      "Epoch 180/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 404474396672.0000 - val_loss: 1935617163264.0000\n",
      "Epoch 181/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 399221981184.0000 - val_loss: 1935192752128.0000\n",
      "Epoch 182/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 394427301888.0000 - val_loss: 1934529265664.0000\n",
      "Epoch 183/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 389184258048.0000 - val_loss: 1934318764032.0000\n",
      "Epoch 184/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 384592412672.0000 - val_loss: 1933403357184.0000\n",
      "Epoch 185/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 379059961856.0000 - val_loss: 1933057982464.0000\n",
      "Epoch 186/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 374400090112.0000 - val_loss: 1932499746816.0000\n",
      "Epoch 187/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 369721016320.0000 - val_loss: 1932096831488.0000\n",
      "Epoch 188/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 365028147200.0000 - val_loss: 1931657216000.0000\n",
      "Epoch 189/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 360605319168.0000 - val_loss: 1931264393216.0000\n",
      "Epoch 190/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 356243374080.0000 - val_loss: 1930918887424.0000\n",
      "Epoch 191/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 351713427456.0000 - val_loss: 1930522001408.0000\n",
      "Epoch 192/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 347484454912.0000 - val_loss: 1930349117440.0000\n",
      "Epoch 193/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 343243554816.0000 - val_loss: 1929853140992.0000\n",
      "Epoch 194/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 339152240640.0000 - val_loss: 1929607380992.0000\n",
      "Epoch 195/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 335301607424.0000 - val_loss: 1929342222336.0000\n",
      "Epoch 196/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163/163 [==============================] - 0s 1ms/step - loss: 331432787968.0000 - val_loss: 1929138929664.0000\n",
      "Epoch 197/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 327883456512.0000 - val_loss: 1929032237056.0000\n",
      "Epoch 198/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 324118544384.0000 - val_loss: 1928812298240.0000\n",
      "Epoch 199/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 320592019456.0000 - val_loss: 1928686993408.0000\n",
      "Epoch 200/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 317239885824.0000 - val_loss: 1928504410112.0000\n",
      "Epoch 201/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 314019610624.0000 - val_loss: 1928394178560.0000\n",
      "Epoch 202/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 310957309952.0000 - val_loss: 1928313700352.0000\n",
      "Epoch 203/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 307868532736.0000 - val_loss: 1928332705792.0000\n",
      "Epoch 204/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 304799350784.0000 - val_loss: 1928172273664.0000\n",
      "Epoch 205/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 301960134656.0000 - val_loss: 1928261533696.0000\n",
      "Epoch 206/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 299488018432.0000 - val_loss: 1928201895936.0000\n",
      "Epoch 207/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 296682258432.0000 - val_loss: 1928201109504.0000\n",
      "Epoch 208/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 294110396416.0000 - val_loss: 1928297840640.0000\n",
      "Epoch 209/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 291773906944.0000 - val_loss: 1928390377472.0000\n",
      "Epoch 210/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 289607516160.0000 - val_loss: 1928499953664.0000\n",
      "Epoch 211/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 287491391488.0000 - val_loss: 1928631549952.0000\n",
      "Epoch 212/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 285512728576.0000 - val_loss: 1928922136576.0000\n",
      "Epoch 213/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 283525382144.0000 - val_loss: 1928898936832.0000\n",
      "Epoch 214/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 281775800320.0000 - val_loss: 1929184673792.0000\n",
      "Epoch 215/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 280139792384.0000 - val_loss: 1929303425024.0000\n",
      "Epoch 216/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 278662283264.0000 - val_loss: 1929553379328.0000\n",
      "Epoch 217/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 277445214208.0000 - val_loss: 1929843048448.0000\n",
      "Epoch 218/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 276074594304.0000 - val_loss: 1930111352832.0000\n",
      "Epoch 219/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 274978439168.0000 - val_loss: 1930355802112.0000\n",
      "Epoch 220/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 273942970368.0000 - val_loss: 1930676011008.0000\n",
      "Epoch 221/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 273111171072.0000 - val_loss: 1930927276032.0000\n",
      "Epoch 222/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 272186671104.0000 - val_loss: 1931235557376.0000\n",
      "Epoch 223/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 271349481472.0000 - val_loss: 1931561140224.0000\n",
      "Epoch 224/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 270716698624.0000 - val_loss: 1931844911104.0000\n",
      "Epoch 225/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 270086356992.0000 - val_loss: 1932139036672.0000\n",
      "Epoch 226/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 269576929280.0000 - val_loss: 1932471828480.0000\n",
      "Epoch 227/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 269184270336.0000 - val_loss: 1932733448192.0000\n",
      "Epoch 228/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 268761415680.0000 - val_loss: 1933032030208.0000\n",
      "Epoch 229/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 268413894656.0000 - val_loss: 1933335592960.0000\n",
      "Epoch 230/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 268177178624.0000 - val_loss: 1933621198848.0000\n",
      "Epoch 231/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 267958272000.0000 - val_loss: 1933862502400.0000\n",
      "Epoch 232/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 267746017280.0000 - val_loss: 1934130937856.0000\n",
      "Epoch 233/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 267595857920.0000 - val_loss: 1934375387136.0000\n",
      "Epoch 234/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 267534336000.0000 - val_loss: 1934617870336.0000\n",
      "Epoch 235/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 267452940288.0000 - val_loss: 1934814216192.0000\n",
      "Epoch 236/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 267297767424.0000 - val_loss: 1935070986240.0000\n",
      "Epoch 237/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 267270160384.0000 - val_loss: 1935162867712.0000\n",
      "Epoch 238/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 267196088320.0000 - val_loss: 1935390801920.0000\n",
      "Epoch 239/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 267144085504.0000 - val_loss: 1935496052736.0000\n",
      "Epoch 240/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 267106877440.0000 - val_loss: 1935631450112.0000\n",
      "Epoch 241/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 267118346240.0000 - val_loss: 1935756623872.0000\n",
      "Epoch 242/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 267268227072.0000 - val_loss: 1935911682048.0000\n",
      "Epoch 243/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 267057954816.0000 - val_loss: 1936009986048.0000\n",
      "Epoch 244/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 267038638080.0000 - val_loss: 1936105799680.0000\n",
      "Epoch 245/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 267045339136.0000 - val_loss: 1936161767424.0000\n",
      "Epoch 246/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 266997645312.0000 - val_loss: 1936250372096.0000\n",
      "Epoch 247/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 267026759680.0000 - val_loss: 1936310534144.0000\n",
      "Epoch 248/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 266947264512.0000 - val_loss: 1936466903040.0000\n",
      "Epoch 249/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 267013914624.0000 - val_loss: 1936476209152.0000\n",
      "Epoch 250/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 266964631552.0000 - val_loss: 1936489971712.0000\n",
      "Epoch 251/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 266958667776.0000 - val_loss: 1936529424384.0000\n",
      "Epoch 252/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 266949394432.0000 - val_loss: 1936556163072.0000\n",
      "Epoch 253/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 266939269120.0000 - val_loss: 1936637165568.0000\n",
      "Epoch 254/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 266954964992.0000 - val_loss: 1936690642944.0000\n",
      "Epoch 255/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 266969055232.0000 - val_loss: 1936681336832.0000\n",
      "Epoch 256/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 266909777920.0000 - val_loss: 1936801136640.0000\n",
      "Epoch 257/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 266883219456.0000 - val_loss: 1936873357312.0000\n",
      "Epoch 258/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 266948427776.0000 - val_loss: 1936890527744.0000\n",
      "Epoch 259/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 266919936000.0000 - val_loss: 1936844783616.0000\n",
      "Epoch 260/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 266927603712.0000 - val_loss: 1936933912576.0000\n",
      "Epoch 261/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163/163 [==============================] - 0s 1ms/step - loss: 266918952960.0000 - val_loss: 1936912547840.0000\n",
      "Epoch 262/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 266894524416.0000 - val_loss: 1936986472448.0000\n",
      "Epoch 263/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 266920181760.0000 - val_loss: 1936991059968.0000\n",
      "Epoch 264/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 266903732224.0000 - val_loss: 1937037590528.0000\n",
      "Epoch 265/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 266892132352.0000 - val_loss: 1937042178048.0000\n",
      "Epoch 266/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 266900684800.0000 - val_loss: 1937078091776.0000\n",
      "Epoch 267/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 266885464064.0000 - val_loss: 1937063936000.0000\n",
      "Epoch 268/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 266892312576.0000 - val_loss: 1937087528960.0000\n",
      "Epoch 269/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 266895835136.0000 - val_loss: 1937089626112.0000\n",
      "Epoch 270/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 266829037568.0000 - val_loss: 1937125539840.0000\n",
      "Epoch 271/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 266832625664.0000 - val_loss: 1937182031872.0000\n",
      "Epoch 272/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 266926194688.0000 - val_loss: 1937177968640.0000\n",
      "Epoch 273/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 266856988672.0000 - val_loss: 1937185964032.0000\n",
      "Epoch 274/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 266881974272.0000 - val_loss: 1937183342592.0000\n",
      "Epoch 275/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 266825334784.0000 - val_loss: 1937241407488.0000\n",
      "Epoch 276/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 266861576192.0000 - val_loss: 1937248485376.0000\n",
      "Epoch 277/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 266840276992.0000 - val_loss: 1937192124416.0000\n",
      "Epoch 278/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 266844635136.0000 - val_loss: 1937232101376.0000\n",
      "Epoch 279/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 266854023168.0000 - val_loss: 1937244684288.0000\n",
      "Epoch 280/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 266819158016.0000 - val_loss: 1937257529344.0000\n",
      "Epoch 281/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 266807066624.0000 - val_loss: 1937267621888.0000\n",
      "Epoch 282/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 266836738048.0000 - val_loss: 1937261592576.0000\n",
      "Epoch 283/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 266804412416.0000 - val_loss: 1937313497088.0000\n",
      "Epoch 284/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 266788241408.0000 - val_loss: 1937298161664.0000\n",
      "Epoch 285/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 266836410368.0000 - val_loss: 1937302749184.0000\n",
      "Epoch 286/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 266770350080.0000 - val_loss: 1937316249600.0000\n",
      "Epoch 287/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 266827350016.0000 - val_loss: 1937325031424.0000\n",
      "Epoch 288/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 266788552704.0000 - val_loss: 1937350721536.0000\n",
      "Epoch 289/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 266831265792.0000 - val_loss: 1937332371456.0000\n",
      "Epoch 290/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 266775199744.0000 - val_loss: 1937366319104.0000\n",
      "Epoch 291/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 266803068928.0000 - val_loss: 1937365401600.0000\n",
      "Epoch 292/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 266804494336.0000 - val_loss: 1937405509632.0000\n",
      "Epoch 293/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 266823303168.0000 - val_loss: 1937426350080.0000\n",
      "Epoch 294/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 266839523328.0000 - val_loss: 1937370906624.0000\n",
      "Epoch 295/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 267062181888.0000 - val_loss: 1937448894464.0000\n",
      "Epoch 296/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 266824564736.0000 - val_loss: 1937392533504.0000\n",
      "Epoch 297/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 266786357248.0000 - val_loss: 1937437622272.0000\n",
      "Epoch 298/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 266788470784.0000 - val_loss: 1937420189696.0000\n",
      "Epoch 299/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 266771333120.0000 - val_loss: 1937431855104.0000\n",
      "Epoch 300/300\n",
      "163/163 [==============================] - 0s 1ms/step - loss: 266783391744.0000 - val_loss: 1937430675456.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_scaled, y_train, batch_size=32, epochs=300, validation_split=0.1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "11ca224d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e2ae904f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e8f9fdc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 35667706972.80\n",
      "R-squared (R2): 0.81\n"
     ]
    }
   ],
   "source": [
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
    "print(f\"R-squared (R2): {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "50e5492e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Contract_prediction_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a62593fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scaler.pkl']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(scaler, 'scaler.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
